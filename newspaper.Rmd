---
title: "Newspapers in Times of Low Advertising Revenues"
author: "Zikun (Alex) Xu"
date: "12/22/2020"
output:
  html_document:default
    df_print: paged
  word_document: default
  pdf_document: default
---

Author: Zikun (Alex) Xu
Date: 12/22/2020
Github repo: https://github.com/xuzi9/final

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Apply libraries that are used in this paper
library(tidyverse)
library(broom)
library(here)
library(here)
library(haven)
library(huxtable)
library(scales)
library(tinytex)
library(tidyverse)
```

# Abstract



# Introduction

In this study, we reproduce the key findings and analyze the data referred from Angelucci and Cage's "Newspapers in Times of Low Advertising Revenues" paper. This paper finds robust evidence that examines the effect of a decrease in the amount of journalist-intensive content produced and the reduction of subscription prices. This data-set was built on newspapers from France between the years 1960 and 1974. As newspaper publishing companies reduce the amount of money invested into journalistic intensive content, specifically due to a decrease in advertising revenue, a difference in differences analysis was performed right between the introduction of television broadcast and advertising was widely accepted. 

Regressions were modeled linearly between the consequences of newspapers' content and the impact of reduction of ad revenue. The paper talks about an example that caught their interest as advertisement revenues for US newspaper companies decreased by almost $30 billion between 2000 and 2019, and average number of journalist per newspaper decreased by nearly 16%. While the introduction of online media and "internet driven" news content has driven the old fashioned newspaper industry economically slow and heavy decrease in viewership, the precise reasons have not been thoroughly analyzed. By giving insight to the relationship between advertisement revenues and newspapers' choices relating to the size of their newsroom, the amount of news being produced, and the different pricing strategies, we were able to find out why we see a decline in advertisement companies' willingness to pay for consumers' attention. 

The alternative to newspaper - television platforms - allows advertisement that specifically targets an individual or a group for different purposes such as using a search engine to find specific genre of products. In this paper, we build a model in which the newspaper companies chooses the size of newsroom, prices it charges for the paper, and prices it charges for advertisers. The results of this framework allows us to understand if a relationship between advertising revenues, the number of journalists, and the composition of readership exists and what consequences does an increase or decrease in revenues conclude. Specifically, this model predicts that a drop in advertising revenues may or may not cause a decrease in the amount of journalistic content produced, an increase or decrease in reader prices, and a readjustment in the attention of the readership. 

The results of these predictions provides evidence that this reform can be plausibly interpreted as an exogenous and negative shock to the advertising side of the newspaper industry. With these results, we can identify the specific policy or application changes such as the policy where advertisements were only allowed for a few minutes per day and the fact that the quality of televisions were very new around 1970s and televised content were not of high quality. This would lead to a conclusion that the introduction of television advertising sent a direct shock to the advertisement of the newspaper industry and a rather minimal shock to the ability to access content on the reader's side. 



# Data

The data-set that was collected for the use of this paper constructed of an annual balanced panel data-set on local and national newspapers between the years 1960 and 1974. Different sources of paper data were digitized and merged from various historical sources. The French Ministry of Information gave data on prices, revenues, and circulation as newspaper companies were required to report their revenues and prices. 

In the data-set, a total of 1196 observations and 52 different variables were identified. Information on subscription prices was calculated by dividing annual subscription prices by the total number of issues in that year. Other variables were included such as the number of issues per year, sales revenue, and advertising revenue, for the purpose of comprehensively reviewing all factors that may lead to the prediction of the exogenous and negative shock to the advertisements in newspapers caused by the decrease in revenue and viewership. A total of 68 local newspapers were sampled, which is a large portion of the local daily newspaper industry and the only ones that were available in the Ministry's archive at the time. An additional 12 national newspapers were sampled circulating between 1960 and 1974. On average, 63 of these newspapers acquire 63 journalists during the time period which is one of the variables that were used to identify newspapers' quality or quantity for journalistic-intensive content. Out of the 12 national newspapers, only 11 contained revenue data, and out of the 68 local newspapers only 63 had. Therefore a total of 6 newspapers had to be excluded from this research which may cause slight bias. The assumption that was made is that this sample had to contain equals amount of observations for the purpose of predictions made from models in the future. 

One of the main predictors, advertising prices and quantity, data was collected on both price and quantity for the purpose of neglecting the effects of changes in advertisement revenue driven by a change in advertisement prices and quantity. The data on advertising prices was specifically the list price for each column inch of advertising space on newspapers. One major downside and limitation of using listing prices was that often times, discounts were commonly offered in the newspaper industry that creates some bias between list prices and actual prices with no uncertainty. Therefore, an assumption of using list price as a relevant measure of advertising prices as long as discounts were not factored into the actual data. 

As we can see in figure 1, advertising revenues in 1967 and 1974 respectively for national newspapers, local newspapers, and television. From these values we can see a distinct benefit of revenue generated from newspapers than televisions, especially before 1974 when television media was not developed and widespread at the time. Also, the data that was collected for revenues on television was done altogether through the website of the INA, National Audiovisual Institute. Advertisement revenue for newspapers however, was collected through 25 different categories ranging from food, cars, and other consumer goods. A differentiation between local and national advertisements helped with further distinguish the effects of these decreased revenues on either local or national scales of newspaper content. Given the wide range of variables, evidence 


```{r data, fig.cap=c("Table 1."), echo=FALSE}
#Read the dta file, similar to read_csv()
newspapers <- read_dta(here::here("Angelucci_Cage_AEJMicro_dataset.dta"))

#Filter out to only use the variables we need
newspapers_filtered <- 
  newspapers %>% 
  dplyr::select(year, id_news, after_national, local, national, # Diff in diff variables
         ra_cst, qtotal, ads_p4_cst, ads_s, # Advertising side dependents
         ps_cst, po_cst, qtotal, qs_s, rs_cst) %>% #Reader side dependents
  mutate(ra_cst_div_qtotal = ra_cst / qtotal) %>% # An advertising side dependents needs to be built
  mutate_at(vars(id_news, after_national, local, national), ~as.factor(.)) %>% # Change some to factors
  mutate(year = as.integer(year))
```


```{r, echo=FALSE}

#Shows the revenues of Local and National newspaper companies of these years
newspapers %>% 
  mutate(type = if_else(local == 1, "Local", "National")) %>% 
  ggplot(aes(x = year, y = ra_cst)) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(labels = dollar_format(prefix="$", suffix = "M", scale = 0.000001)) +
  labs(x = "Year",
       y = "Advertising revenue", title = "Figure 1. Local vs National advertising revenue") +
  facet_wrap(vars(type),
               nrow = 2) +
  theme_classic() +
  geom_vline(xintercept = 1966.5, linetype = "dashed")

```


# Model
The model that we are using is:
$$ln(y_{n,t})= \beta_0 + \beta_1(X_{national}*X_{after 1967})+ \lambda_n + \gamma_t + \epsilon_{n,t}$$
Where $X_{national}$ be an indicator variable for national newspaper and $X_{after1967}$ be a dummy variable that only applies for observations after 1967 when the news industry transitions into television media. Also, $n$ is the indexes and $t$ is the number of years (being between 1960 and 1974). We also use $\lambda_n$ for the fixed effects of each newspaper as well as $\gamma_t$ for the fixed effect of each year. Since the newspaper and year variables are fixed effects, the $\beta_1$ is what we want are interested in which measures the effect for national newspapers with the new televised advertisement approaches of companies, in which is compared to the response variable, the number of journalists employed for journalistic content. The response variable $y_{n,t}$ is the outcome variable that predicts the outcomes of advertisement transitioning to television on revenue, newspaper prices and quantity. The $\epsilon_{n,t}$ is the newspaper-year shock in which standard error are dispersed around the newspaper level. The major assumption made with this model is that between national and local newspaper, the response variable's $(y_{n,t})$ results apply for both levels of newspapers without the inclusion of the treatment - which prompts deviation from the general trends. The evidence for this assumption relies of the fact that French television companies was state-owned between 1950s and 1980s, therefore there was no interaction between television companies and newspaper companies whether it be local or national. The decision by the French government to introduce advertisement on television was a external factor for newspaper companies. In our OLS models, four regressions were performed to get the results for revenue from sales, revenues from advertisement , display ad rate, and percentage share of advertising. With the same concept we proceed to model 4 different aspects of the impact after television advertisement was introduced being: effects on the advertisement side of the market, effects on the  reader side of the market, and effects on readership. 

## Table 1. Advertising Side
```{r, echo=FALSE}
# Advertising side
ad_revenue <- lm(log(ra_cst) ~ after_national + id_news + year, data = newspapers_filtered)
#Revenue affected by 
#summary(ad_revenue)
ad_revenue_div_circulation <- lm(log(ra_cst_div_qtotal) ~ after_national + id_news + year, data = newspapers_filtered)
ad_price <- lm(log(ads_p4_cst) ~ after_national + id_news + year, data = newspapers_filtered)
ad_space <- lm(log(ads_s) ~ after_national + id_news + year, data = newspapers_filtered)


#This removes the coefficients to be shown in the summary table
omit_me <- c("(Intercept)", "id_news3", "id_news6", "id_news7", "id_news13", 
             "id_news16", "id_news25", "id_news28", "id_news34", "id_news38", 
             "id_news44", "id_news48", "id_news51", "id_news53", "id_news54", 
             "id_news57", "id_news60", "id_news62", "id_news66", "id_news67", 
             "id_news70", "id_news71", "id_news72", "id_news80", "id_news82", 
             "id_news88", "id_news95", "id_news97", "id_news98", "id_news103", 
             "id_news105", "id_news106", "id_news118", "id_news119", "id_news127", 
             "id_news136", "id_news138", "id_news148", "id_news151", "id_news153", 
             "id_news154", "id_news157", "id_news158", "id_news161", "id_news163", 
             "id_news167", "id_news169", "id_news179", "id_news184", "id_news185", 
             "id_news187", "id_news196", "id_news206", "id_news210", "id_news212", 
             "id_news213", "id_news224", "id_news225", "id_news234", "id_news236", 
             "id_news245", "id_news247", "id_news310", "id_news452", "id_news467", 
             "id_news469", "id_news480", "id_news20040", "id_news20345", 
             "id_news20346", "id_news20347", "id_news20352", "id_news20354", 
             "id_news21006", "id_news21025", "id_news21173", "id_news21176", 
             "id_news33718", "id_news34689", "id_news73")

huxreg("Ad. rev." = ad_revenue, 
       "Ad rev. div. circ." = ad_revenue_div_circulation, 
       "Ad price" = ad_price, 
       "Ad space" = ad_space,
        omit_coefs = omit_me, 
        number_format = 2
        )

```


##Table 2. Consumer Side
We then look at the the prices from the consumer or reader side and consider size and content of different newsroom choices. This helps us analyze how the difference in advertisement revenues since the introduction to television has effected the pricing of newspapers (being unit and subscription prices), their circulation, percentage of subscriptions, and revenue from advertisement. 


```{r, echo=FALSE}

# Consumer side
subscription_price <- lm(log(ps_cst) ~ after_national + id_news + year, data = newspapers_filtered)
unit_price <- lm(log(po_cst) ~ after_national + id_news + year, data = newspapers_filtered)
circulation <- lm(log(qtotal) ~ after_national + id_news + year, data = newspapers_filtered)
share_of_sub <- lm(log(qs_s) ~ after_national + id_news + year, data = newspapers_filtered)
revenue_from_sales <- lm(log(rs_cst) ~ after_national + id_news + year, data = newspapers_filtered)

omit_me <- c("(Intercept)", "id_news3", "id_news6", "id_news7", "id_news13", 
             "id_news16", "id_news25", "id_news28", "id_news34", "id_news38", 
             "id_news44", "id_news48", "id_news51", "id_news53", "id_news54", 
             "id_news57", "id_news60", "id_news62", "id_news66", "id_news67", 
             "id_news70", "id_news71", "id_news72", "id_news80", "id_news82", 
             "id_news88", "id_news95", "id_news97", "id_news98", "id_news103", 
             "id_news105", "id_news106", "id_news118", "id_news119", "id_news127", 
             "id_news136", "id_news138", "id_news148", "id_news151", "id_news153", 
             "id_news154", "id_news157", "id_news158", "id_news161", "id_news163", 
             "id_news167", "id_news169", "id_news179", "id_news184", "id_news185", 
             "id_news187", "id_news196", "id_news206", "id_news210", "id_news212", 
             "id_news213", "id_news224", "id_news225", "id_news234", "id_news236", 
             "id_news245", "id_news247", "id_news310", "id_news452", "id_news467", 
             "id_news469", "id_news480", "id_news20040", "id_news20345", 
             "id_news20346", "id_news20347", "id_news20352", "id_news20354", 
             "id_news21006", "id_news21025", "id_news21173", "id_news21176", 
             "id_news33718", "id_news34689", "id_news73")

huxreg("Subscription price" = subscription_price, 
       "Unit price" = unit_price, 
       "Circulation" = circulation, 
       "Share of sub" = share_of_sub,
       "Revenue from sales" = revenue_from_sales,
       omit_coefs = omit_me, 
       number_format = 2
       )

```

#Table 3. Quality

```{r, echo=FALSE}
#Model for Quality each of the explanatory variables
num_journ <- lm(log(nb_journ) ~ after_national + id_news + year, data = newspapers)
avg_payroll <- lm(ln_av_payroll_cst ~ after_national + id_news + year, data = newspapers)
pages <- lm(log(pages) ~ after_national + id_news + year, data = newspapers)
news_hole <- lm(log(news_hole) ~ after_national + id_news + year, data = newspapers)
share_hard <- lm(log(share_Hard) ~ after_national + id_news + year, data = newspapers)

omit_me <- c("(Intercept)", "id_news3", "id_news6", "id_news7", "id_news13", 
             "id_news16", "id_news25", "id_news28", "id_news34", "id_news38", 
             "id_news44", "id_news48", "id_news51", "id_news53", "id_news54", 
             "id_news57", "id_news60", "id_news62", "id_news66", "id_news67", 
             "id_news70", "id_news71", "id_news72", "id_news80", "id_news82", 
             "id_news88", "id_news95", "id_news97", "id_news98", "id_news103", 
             "id_news105", "id_news106", "id_news118", "id_news119", "id_news127", 
             "id_news136", "id_news138", "id_news148", "id_news151", "id_news153", 
             "id_news154", "id_news157", "id_news158", "id_news161", "id_news163", 
             "id_news167", "id_news169", "id_news179", "id_news184", "id_news185", 
             "id_news187", "id_news196", "id_news206", "id_news210", "id_news212", 
             "id_news213", "id_news224", "id_news225", "id_news234", "id_news236", 
             "id_news245", "id_news247", "id_news310", "id_news452", "id_news467", 
             "id_news469", "id_news480", "id_news20040", "id_news20345", 
             "id_news20346", "id_news20347", "id_news20352", "id_news20354", 
             "id_news21006", "id_news21025", "id_news21173", "id_news21176", 
             "id_news33718", "id_news34689", "id_news73")

#Display in a table
huxreg("Number of Journalist" = num_journ, 
       "Average Payroll" = avg_payroll, 
       "Number of Pages" = pages, 
       "News Hole" = news_hole,
       "Share of hard news on front page" = share_hard,
       omit_coefs = omit_me, 
       number_format = 2
       )
```


#Table 4. Readership
```{r, echo=FALSE}
#Model for Readership each of the explanatory variables
num_journ <- lm(log(nb_journ) ~ after_national + id_news + year, data = newspapers)
avg_payroll <- lm(ln_av_payroll_cst ~ after_national + id_news + year, data = newspapers)
pages <- lm(log(pages) ~ after_national + id_news + year, data = newspapers)
news_hole <- lm(log(news_hole) ~ after_national + id_news + year, data = newspapers)
share_hard <- lm(log(share_Hard) ~ after_national + id_news + year, data = newspapers)

omit_me <- c("(Intercept)", "id_news3", "id_news6", "id_news7", "id_news13", 
             "id_news16", "id_news25", "id_news28", "id_news34", "id_news38", 
             "id_news44", "id_news48", "id_news51", "id_news53", "id_news54", 
             "id_news57", "id_news60", "id_news62", "id_news66", "id_news67", 
             "id_news70", "id_news71", "id_news72", "id_news80", "id_news82", 
             "id_news88", "id_news95", "id_news97", "id_news98", "id_news103", 
             "id_news105", "id_news106", "id_news118", "id_news119", "id_news127", 
             "id_news136", "id_news138", "id_news148", "id_news151", "id_news153", 
             "id_news154", "id_news157", "id_news158", "id_news161", "id_news163", 
             "id_news167", "id_news169", "id_news179", "id_news184", "id_news185", 
             "id_news187", "id_news196", "id_news206", "id_news210", "id_news212", 
             "id_news213", "id_news224", "id_news225", "id_news234", "id_news236", 
             "id_news245", "id_news247", "id_news310", "id_news452", "id_news467", 
             "id_news469", "id_news480", "id_news20040", "id_news20345", 
             "id_news20346", "id_news20347", "id_news20352", "id_news20354", 
             "id_news21006", "id_news21025", "id_news21173", "id_news21176", 
             "id_news33718", "id_news34689", "id_news73")

huxreg("Number of Journalist" = num_journ, 
       "Average Payroll" = avg_payroll, 
       "Number of Pages" = pages, 
       "News Hole" = news_hole,
       "Share of hard news on front page" = share_hard,
       omit_coefs = omit_me, 
       number_format = 2
       )
```

#Results
In the Table 1 for the results of the effects on the advertising side of the market, our prediction is that advertising revenues will decrease and have a negative shock with the implementation of televised advertisements and as we saw in the table 


#Discussion










# References
- Angelucci, Charles, and Julia Cagé, 2019, ‘Newspapers in times of low advertising revenues’, American Economic Journal: Microeconomics, vol. 11, no. 3, pp. 319-364, DOI: 10.1257/mic.20170306, available at: https://www.aeaweb.org/articles?id=10.1257/mic.20170306.

- Canadian Demographics at a Glance. (2014). Statistics Canada. Catalogue no. 91-003-X.

- Hadley Wickham and Evan Miller (2020). haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files. R package
  version 2.3.1. https://CRAN.R-project.org/package=haven

- H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.

- R Core Team (2020). R: A language and environment for statistical
  computing. R Foundation for Statistical Computing, Vienna, Austria.
  URL https://www.R-project.org/.

- Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686
  
  
- Xie Y (2019). “TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.” TUGboat, 30–32. http://tug.org/TUGboat/Contents/contents40-1.html.